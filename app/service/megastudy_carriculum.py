from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
import pandas as pd
import shutil
import os
import re
from selenium.webdriver.support import expected_conditions as EC
import time
import json
from app.utils.s3_utils import upload_to_s3


def create_driver():
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    driver = webdriver.Chrome(options=options)
    return driver


def scrape_megastudy_course(driver, url):
    data = {
        "url": url,
        "platform": "megastudy",
        "is_paid": True,
        "price": None,
        "lectures": [],  # ëŒ€ë¶€ë¶„ ì—†ê±°ë‚˜ ì ‘ê·¼ ë¶ˆê°€
    }

    driver.get(url)

    try:
        # ê°•ì˜ëª…
        title = driver.find_element(
            By.CSS_SELECTOR,
            "#wrap_2014 > div.column_main > div.column_right > div.l_lst2018 > div.bx_detail > div.bx_detail--infos > div > p.lstedu_bookinfo--tit",
        ).text.strip()
        data["title"] = title
    except:
        data["title"] = ""

    try:
        # ê°•ì‚¬ëª…
        teacher_subject = (
            driver.find_element(
                By.CSS_SELECTOR,
                "#wrap_2014 > div.column_main > div.column_right > div.l_lst2018 > div.bx_detail > div.bx_detail--infos > div > p.lstedu_bookinfo--teacher > strong > a",
            )
            .text.strip()
            .split(" ")
        )
        match = re.compile("\[([^]]+)\]")
        subject = match.findall(teacher_subject[0])
        teacher = teacher_subject[1]
        data["teacher"] = teacher
        data["subject"] = subject[0]
    except:
        data["teacher"] = ""
        data["subject"] = ""

    # ê°•ì¢Œ ìœ í˜• ì¶”ì¶œ
    try:
        type = driver.find_element(
            By.CSS_SELECTOR,
            "#wrap_2014 > div.column_main > div.column_right > div.l_lst2018 > div.bx_detail > div.bx_detail--infos > div > ul > li:nth-child(1) > dl:nth-child(2) > dd",
        ).text.strip()
        data["type"] = type
    except:
        data["type"] = ""

    # ì´ ê°•ì˜ ìˆ˜
    try:
        total_lectures = driver.find_element(
            By.CSS_SELECTOR,
            "#wrap_2014 > div.column_main > div.column_right > div.l_lst2018 > div.bx_detail > div.bx_detail--infos > div > ul > li:nth-child(2) > dl:nth-child(1) > dd",
        ).text.strip()
        match = re.search(r"ì´\s*(\d+)ê°•", total_lectures)
        data["total_lectures"] = (match.group(1) + "ê°•").strip()
    except:
        data["total_lectures"] = 0

    # ìˆ˜ê°• ê¸°ê°„
    try:
        duration_total = driver.find_element(
            By.CSS_SELECTOR,
            "#wrap_2014 > div.column_main > div.column_right > div.l_lst2018 > div.bx_detail > div.bx_detail--infos > div > ul > li:nth-child(2) > dl:nth-child(2) > dd",
        ).text.strip()
        data["duration_total"] = duration_total
    except:
        data["duration_total"] = ""

    try:
        # ìˆ˜ê°• ëŒ€ìƒ ë° ê³¼ëª© ì •ë³´ (íƒ€ê²Ÿ/ê³¼ëª©ëª…/í•™ë…„ ë“± í¬í•¨ë¨)
        info_area = driver.find_element(
            By.CSS_SELECTOR,
            "#wrap_2014 > div.column_main > div.column_right > div.l_lst2018 > div.bx_detail > div.bx_detail--infos > div > ul > li:nth-child(1) > dl:nth-child(1) > dd",
        ).text.strip()
        data["grade"] = info_area
    except:
        data["grade"] = ""

    try:
        # ê°•ì¢Œ ì„¤ëª…
        description = driver.find_element(By.CSS_SELECTOR, ".editArea").text.strip()
        data["description"] = description
    except:
        data["description"] = ""

    try:
        # ê°€ê²© ì •ë³´
        price_text = driver.find_element(
            By.CSS_SELECTOR, ".lstedu_bxitem .bx_price--info"
        ).text
        price = int(price_text.replace(",", "").replace("ì›", "").strip())
        data["price"] = price
        data["is_paid"] = price > 0
    except:
        data["price"] = None
        data["is_paid"] = True  # ë©”ê°€ìŠ¤í„°ë””ëŠ” ëŒ€ë¶€ë¶„ ìœ ë£Œ

    try:
        # ê°€ê²© ì •ë³´
        lectures_row = driver.find_elements(
            By.CSS_SELECTOR, "#scrollTab2 .tb_char_opt tbody tr"
        )

        for row in lectures_row:
            lecture_data = {}
            try:
                # ì—¬ê¸°ì„œ ë¶€í„° ë‹¤ì‹œ ì‹œì‘, ì‹œê°„ ì •ë³´, ì œëª© ì œëŒ€ë¡œ ë‚˜ëˆ„ê²Œ ë” ë§Œë“¤ê¸°ê¸°
                data_split = row.text.split("\n")
                lecture_data["title"] = data_split[0].strip()  # ê°•ì˜ ì œëª©
                lecture_data["info"] = (
                    data_split[1].strip() if len(data_split) > 1 else ""
                )  # ê°•ì˜ ì •ë³´
                print(lecture_data["title"])
                print(lecture_data["info"])
                data["lectures"].append(lecture_data)
            except:
                continue

    except:
        data["price"] = None
        data["is_paid"] = True  # ë©”ê°€ìŠ¤í„°ë””ëŠ” ëŒ€ë¶€ë¶„ ìœ ë£Œ

    return data


def crawling_mega():
    try:
        with open("mega_urls.json", encoding="utf-8") as f:
            url_items = json.load(f)

        driver = create_driver()

        # ëŒ€ê³¼ëª©ë³„ ë°ì´í„° ì €ì¥
        subject_course_map = {}
        subject_lecture_map = {}

        for item in url_items:
            url = item["url"]
            subject_full = item["subject"]

            # ëŒ€ê³¼ëª© ì¶”ì¶œ (ì˜ˆ: "êµ­ì–´-ë¬¸í•™" â†’ "êµ­ì–´")
            major_subject = subject_full.split("-")[0]

            # course_id ì¶”ì¶œ
            match = re.search(r"CHR_CD=(\d+)", url)
            course_id = match.group(1) if match else f"unknown_{int(time.time())}"

            # í¬ë¡¤ë§
            data = scrape_megastudy_course(driver, url)

            # course ë©”íƒ€ ë°ì´í„°
            course_meta = {
                "course_id": course_id,
                "title": data.get("title", ""),
                "teacher": data.get("teacher", ""),
                "subject": subject_full,
                "description": data.get("description", ""),
                "reviews": data.get("reviews", 0),  # ë©”ê°€ìŠ¤í„°ë””ëŠ” ë¦¬ë·° ë°ì´í„° ì—†ìœ¼ë©´ 0
                "grade": data.get("grade", ""),
                "platform": data.get("platform", ""),
                "is_paid": data.get("is_paid", False),
                "price": data.get("price", 0),
                "difficulty_level": data.get(
                    "dificulty_level", ""
                ),  # ë‚œì´ë„ ì •ë³´ ë¹„ì–´ìˆìŒ
                "url": data.get("url", ""),
            }
            subject_course_map.setdefault(major_subject, []).append(course_meta)

            # lectures ë°ì´í„°
            lectures = data.get("lectures", [])
            for lecture in lectures:
                lecture_entry = {
                    "course_id": course_id,
                    "title": lecture.get("title", ""),
                    "info": lecture.get("info", ""),
                }
                subject_lecture_map.setdefault(major_subject, []).append(lecture_entry)

            print(f"[ì™„ë£Œ] {course_id} ({subject_full})")

        driver.quit()

        # ê³¼ëª©ë³„ CSV ì €ì¥ ë° S3 ì—…ë¡œë“œ
        for subject, course_list in subject_course_map.items():
            courses_df = pd.DataFrame(course_list)
            lectures_df = pd.DataFrame(subject_lecture_map.get(subject, []))

            courses_filename = f"{subject}_mega_courses.csv"
            lectures_filename = f"{subject}_mega_lectures.csv"

            # S3 ì—…ë¡œë“œë§Œ ìˆ˜í–‰
            upload_to_s3(courses_df, courses_filename)
            upload_to_s3(lectures_df, lectures_filename)

            print(f"âœ… S3 ì—…ë¡œë“œ ì™„ë£Œ: {subject}")

        return "ğŸ‰ ëª¨ë“  ë©”ê°€ìŠ¤í„°ë”” ê³¼ëª©ë³„ S3 ì—…ë¡œë“œ ì™„ë£Œ"
    except Exception as e:
        return f"âŒ Error occurred: {str(e)}"
